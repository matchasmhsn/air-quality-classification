# -*- coding: utf-8 -*-
"""projectTA(uus).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1J0_s1B07eQ_XzJOk3RCXkswkT-gvr0sh
"""

pip install numpy pandas tensorflow scikit-learn

import pandas as pd
from sklearn.preprocessing import LabelEncoder, MinMaxScaler
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, ConfusionMatrixDisplay

# Mengimpor dataset
data = pd.read_csv('datafix.csv')

# Memisahkan fitur dan label
X = data.drop('Kategori', axis=1).values
y = data['Kategori'].values

"""# **Preprocessing**"""

from sklearn.preprocessing import LabelEncoder, StandardScaler

# Mengubah label menjadi numerik
label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y)

# Normalisasi fitur
scaler = MinMaxScaler()
X_normalized = scaler.fit_transform(X)

# Menggabungkan fitur yang dinormalisasi dengan label
data_normalized = np.column_stack((X_normalized, y_encoded))

# Membuat DataFrame
columns = [f'Feature_{i+1}' for i in range(X_normalized.shape[1])] + ['Label']
df_normalized = pd.DataFrame(data_normalized, columns=columns)

# Menyimpan ke file CSV
df_normalized.to_csv('data_normalized.csv', index=False)
print("Data yang telah dinormalisasi telah disimpan sebagai 'data_normalized.csv'")

"""# **Pembagian Data Latih & Data Uji**"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
# Melihat jumlah data latih dan data uji
print(f"Jumlah data latih: {len(X_train)}")
print(f"Jumlah data uji: {len(X_test)}")

import pandas as pd

# Misalnya kamu ingin melihat 5 baris pertama dari data latih dan data uji
print("5 Baris Pertama dari Data Latih:")
print(pd.DataFrame(X_train).head())

print("\n5 Baris Pertama dari Data Uji:")
print(pd.DataFrame(X_test).head())

# Menggabungkan X_train dan y_train ke dalam satu DataFrame
train_data = pd.DataFrame(X_train)
train_data['label'] = y_train

# Menggabungkan X_test dan y_test ke dalam satu DataFrame
test_data = pd.DataFrame(X_test)
test_data['label'] = y_test

# Menyimpan ke file CSV
train_data.to_csv('train_data.csv', index=False)
test_data.to_csv('test_data.csv', index=False)

print("Data latih dan data uji telah disimpan sebagai 'train_data.csv' dan 'test_data.csv'.")

"""# **Membangun Model & Pelatihan**"""

from tensorflow.keras.utils import to_categorical

# Jika target asli adalah integer
y_train_categorical = to_categorical(y_train, num_classes=2)  # Ganti 2 dengan jumlah kelas
y_test_categorical = to_categorical(y_test, num_classes=2)

import os
import random
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Activation

# Mengatur seed di berbagai pustaka
os.environ['PYTHONHASHSEED'] = '42'
random.seed(42)
np.random.seed(42)
tf.random.set_seed(42)

# Membangun model
model = Sequential()

# Input layer diikuti oleh hidden layer pertama
model.add(Dense(5, input_dim=6, activation='relu'))  # Hidden layer pertama dengan 5 neuron
model.add(BatchNormalization())
model.add(Dropout(0.2))

# Hidden layer kedua
model.add(Dense(5, activation='relu'))  # Hidden layer kedua dengan 5 neuron
model.add(BatchNormalization())
model.add(Dropout(0.2))

# Hidden layer ketiga
model.add(Dense(10, activation='relu'))  # Hidden layer ketiga dengan 10 neuron

# Output layer
model.add(Dense(2, activation='softmax'))  # Output layer dengan 2 neuron untuk klasifikasi 2 kelas

# Mengompilasi model
optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)  # Menggunakan learning rate yang lebih umum
model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])

# Melatih model
history = model.fit(X_train, y_train_categorical, epochs=200, batch_size=32, validation_split=0.2)

# Evaluasi model
loss, accuracy = model.evaluate(X_test, y_test_categorical)
print(f'Loss: {loss}')
print(f'Accuracy: {accuracy}')

# Melakukan prediksi terhadap seluruh data uji
predictions = model.predict(X_test)

# Membulatkan hasil prediksi ke dua angka desimal
predictions_rounded = np.round(predictions, 2)

# Menampilkan prediksi yang sudah dibulatkan
print("Nilai keluaran dari neuron pada lapisan output untuk semua sampel (dibulatkan):")
print(predictions_rounded)

import pandas as pd

# Melakukan prediksi terhadap seluruh data uji
predictions = model.predict(X_test)

# Mendapatkan kelas prediksi (kelas dengan probabilitas tertinggi)
predicted_classes = np.argmax(predictions, axis=1)

# Membuat dataframe dengan hasil prediksi
df_predictions = pd.DataFrame(predictions, columns=['Probabilitas Kelas 0', 'Probabilitas Kelas 1'])
df_predictions['Kelas Prediksi'] = predicted_classes

# Menyimpan dataframe ke file CSV
df_predictions.to_csv('hasil_prediksi.csv', index=False)

print("Hasil prediksi telah disimpan ke dalam file 'hasil_prediksi.csv'.")

"""# **Confusion Matrix**"""

print(y_test_categorical.shape)  # Periksa dimensi array

from sklearn.metrics import confusion_matrix, accuracy_score
import numpy as np

# Mengonversi y_test dari one-hot encoding ke label integer
y_test_labels = np.argmax(y_test_categorical, axis=1)

# Misalnya, prediksi model
predictions_prob = model.predict(X_test)
predictions = np.argmax(predictions_prob, axis=1)

# Menghitung Confusion Matrix dan Metrik Evaluasi
cm = confusion_matrix(y_test_labels, predictions)
accuracy = accuracy_score(y_test_labels, predictions)
precision = precision_score(y_test_labels, predictions, average='binary')
recall = recall_score(y_test_labels, predictions, average='binary')

# Menampilkan confusion matrix
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_encoder.classes_)
disp.plot(cmap=plt.cm.Blues)
plt.show()

# Menampilkan Metrik Evaluasi
print(f'Confusion Matrix:\n{cm}')
print(f'Accuracy: {accuracy:.4f}')
print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')

# Evaluasi model pada data pelatihan
train_loss, train_accuracy = model.evaluate(X_train, y_train_categorical, verbose=0)
print(f"Akurasi pada data pelatihan: {train_accuracy:.2f}")

# Evaluasi model pada data pengujian
test_loss, test_accuracy = model.evaluate(X_test, y_test_categorical, verbose=0)
print(f"Akurasi pada data pengujian: {test_accuracy:.2f}")

# Konversi kembali ke label asli
predicted_labels = label_encoder.inverse_transform(predictions)
actual_labels = label_encoder.inverse_transform(y_test_labels)

"""# **Grafik Loss dan Accuracy**"""

# Plotting loss dan akurasi
def plot_history(history):
    plt.figure(figsize=(12, 5))

    # Plotting loss
    plt.subplot(1, 2, 1)
    plt.plot(history.history['loss'], label='Training Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.title('Loss during training and validation')
    plt.legend()

    # Plotting accuracy
    plt.subplot(1, 2, 2)
    plt.plot(history.history['accuracy'], label='Training Accuracy')
    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.title('Accuracy during training and validation')
    plt.legend()

    plt.show()

# Menampilkan grafik loss dan akurasi
plot_history(history)

"""# **Hasil Klasifikasi**"""

import pandas as pd

# Konversi hasil prediksi dan label asli ke label teks
predicted_labels = label_encoder.inverse_transform(predictions)
actual_labels = label_encoder.inverse_transform(y_test_labels)

# Buat DataFrame untuk hasil prediksi
results_df = pd.DataFrame({
    'Actual_Label': actual_labels,
    'Predicted_Label': predicted_labels
})

# Menyimpan hasil ke file CSV
results_df.to_csv('data_kualitas_udara_predicted.csv', index=False)
print("Hasil klasifikasi telah disimpan sebagai 'data_kualitas_udara_predicted.csv'")

# Memprediksi pada seluruh data
all_predictions = model.predict(X)
all_predictions = (all_predictions > 0.5).astype(int)